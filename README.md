# ü™ê D√©tection d'Exoplan√®tes : Baseline (Random Forest) vs. Deep Learning (CNN 1D)

![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)

Ce projet compare deux approches de Machine Learning pour la d√©tection d'exoplan√®tes √† partir des courbes de lumi√®re (flux lumineux) des t√©lescopes spatiaux TESS et Kepler.

## 1. L'Hypoth√®se Scientifique üéØ

Un "transit" d'exoplan√®te (le passage de la plan√®te devant son √©toile) cr√©e une signature morphologique identifiable : un "creux" p√©riodique et de courte dur√©e dans la courbe de lumi√®re de l'√©toile.

Ce projet vise √† entra√Æner des mod√®les de Machine Learning √† reconna√Ætre cette signature pour la diff√©rencier du simple bruit de fond ou d'autres variations stellaires.

## 2. La T√¢che de Machine Learning ü§ñ

* **T√¢che** : Classification Binaire Supervis√©e.
* **Input (X)** : Une s√©rie temporelle (courbe de lumi√®re, ex: `~3000+` colonnes `FLUX`).
* **Output (Y)** : Pr√©diction √† 2 classes : `0` (Pas de Plan√®te) ou `1` (Plan√®te D√©tect√©e).

## 3. M√©thodologie (Double Mod√®le) üß†

Pour √©valuer la meilleure approche, nous impl√©mentons et comparons deux mod√®les distincts :

### Partie A : Le Mod√®le de Baseline (Random Forest)

* **Objectif** : √âtablir un score de r√©f√©rence.
* **Mod√®le** : `RandomForestClassifier`.
* **Approche** : Bas√©e sur l'**ing√©nierie de caract√©ristiques (feature engineering)**. Nous traduisons manuellement la s√©rie temporelle brute de 3000+ points en un petit ensemble de caract√©ristiques descriptives (ex: profondeur moyenne des creux, √©cart-type du flux, p√©riodicit√© via autocorr√©lation).

### Partie B : Le Mod√®le Avanc√© (Deep Learning)

* **Objectif** : Battre la baseline en utilisant l'apprentissage de caract√©ristiques.
* **Mod√®le** : R√©seau de Neurones Convolutif 1D (CNN 1D).
* **Approche** : **Aucun feature engineering**. La courbe de lumi√®re brute (vecteur de `~3000+` points) est fournie directement en entr√©e. Le CNN agit comme un d√©tecteur de "forme" (shape) automatique, apprenant √† identifier la morphologie du transit par lui-m√™me.

## 4. Les Donn√©es ‚úÖ

* **Source** : T√©lescope spatial TESS (ou Kepler).
* **Dataset Sugg√©r√©** : [Exoplanet Hunting in TESS Light Curves (Kaggle)](https://www.kaggle.com/datasets/keplersmachines/kepler-labelled-time-series-data)
* **Format** : `train.csv` et `test.csv` contenant un `LABEL` (Y) et `~3000+` colonnes `FLUX` (X).

**Note importante** : Conform√©ment aux bonnes pratiques, les fichiers de donn√©es brutes (`.csv`) sont list√©s dans le `.gitignore` et ne doivent pas √™tre "push√©s" sur ce d√©p√¥t. Pour ex√©cuter le projet, veuillez t√©l√©charger les donn√©es depuis la source Kaggle et les placer dans le dossier `data/raw/`.

## 5. Installation

Pour configurer votre environnement local et ex√©cuter ce projet :

1.  **Clonez le d√©p√¥t :**
    ```bash
    git clone [https://github.com/VOTRE_NOM/exoplanet-detection-ml.git](https://github.com/VOTRE_NOM/exoplanet-detection-ml.git)
    cd exoplanet-detection-ml
    ```

2.  **Cr√©ez un environnement virtuel (recommand√©) :**
    ```bash
    python -m venv venv
    source venv/bin/activate  # Sur Windows: .\venv\Scripts\activate
    ```

3.  **Installez les d√©pendances :**
    ```bash
    pip install -r requirements.txt
    ```

## 6. Utilisation et Workflow

Ce projet utilise un workflow Git structur√© :

* `main` : Branche de production, prot√©g√©e. Les merges ne se font que depuis `develop`.
* `develop` : Branche d'int√©gration principale (branche par d√©faut).
* `feature/...` : Branches de travail pour les nouvelles fonctionnalit√©s.

Tout nouveau code doit √™tre ajout√© via une **Pull Request** d'une branche `feature/` vers `develop`.

### Reproduire les r√©sultats

Les notebooks sont num√©rot√©s et doivent √™tre ex√©cut√©s dans l'ordre :

1.  **`notebooks/01_EDA_and_Preprocessing.ipynb`** :
    * Chargement des donn√©es.
    * Analyse exploratoire (EDA).
    * Nettoyage, imputation des NaN et normalisation (detrending) des courbes de lumi√®re.

2.  **`notebooks/02_RF_Baseline_Model.ipynb`** :
    * G√©n√©ration des caract√©ristiques (feature engineering) via `src/features.py`.
    * Entra√Ænement et √©valuation du `RandomForestClassifier`.

3.  **`notebooks/03_CNN_1D_Model.ipynb`** :
    * Pr√©paration des donn√©es brutes (mise en forme pour Keras/TensorFlow).
    * Construction, entra√Ænement et √©valuation du mod√®le CNN 1D.

4.  **`notebooks/04_Model_Comparison.ipynb`** :
    * Comparaison finale des deux mod√®les.
    * G√©n√©ration des matrices de confusion, calcul des F1-Scores et des courbes/scores PR-AUC.

## 7. Structure du D√©p√¥t

## 8. R√©sultats Attendus (Point 6)

L'√©valuation finale comparera les deux mod√®les. Le dataset √©tant tr√®s d√©s√©quilibr√© (beaucoup plus de non-plan√®tes que de plan√®tes), l'Accuracy n'est pas une bonne m√©trique.

Nous nous concentrerons sur :
* **PR-AUC** (Aire sous la courbe Pr√©cision-Rappel) : La m√©trique principale pour ce type de probl√®me.
* **F1-Score** : L'√©quilibre entre Pr√©cision et Rappel.
* **Matrice de Confusion** : Pour analyser les Faux Positifs et Faux N√©gatifs.

L'hypoth√®se est que le **CNN 1D** obtiendra un score PR-AUC et F1 sup√©rieur, car il est sp√©cifiquement con√ßu pour la d√©tection de motifs dans des s√©quences, surpassant ainsi les caract√©ristiques con√ßues manuellement.

*(TODO: Ins√©rer ici un tableau r√©sum√© des r√©sultats finaux)*

## 9. Licence

Ce projet est publi√© sous la Licence MIT. Voir le fichier `LICENSE` pour plus de d√©tails.